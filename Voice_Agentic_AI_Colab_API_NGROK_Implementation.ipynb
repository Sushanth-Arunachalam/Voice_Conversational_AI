{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YOhpYAzamWDy"
      },
      "outputs": [],
      "source": [
        "!pip install -U langchain langchain-openai langchain-community openai faiss-cpu gtts pydub speechrecognition tenacity fastapi uvicorn --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI, File, UploadFile\n",
        "import openai\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from pydub import AudioSegment\n",
        "import speech_recognition as sr\n",
        "import time\n",
        "from gtts import gTTS\n",
        "from fastapi.responses import FileResponse\n",
        "from io import BytesIO\n",
        "import os\n",
        "import base64\n",
        "\n",
        "# Initialize FastAPI app\n",
        "app = FastAPI()\n",
        "\n",
        "# OpenAI API key\n",
        "openai.api_key = \"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\"  # Replace with your OpenAI API key\n"
      ],
      "metadata": {
        "id": "7atJABcXmgHg"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "\n",
        "# Upload dataset\n",
        "uploaded = files.upload()\n",
        "df = pd.read_csv(next(iter(uploaded)))\n",
        "\n",
        "# Chunk into documents\n",
        "text_data = '\\n'.join(df.astype(str).apply(lambda row: ' '.join(row), axis=1).tolist())\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "docs = splitter.create_documents([text_data])\n",
        "\n",
        "# Embedding setup\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=openai.api_key)\n",
        "\n",
        "# Indexing into FAISS\n",
        "vectorstore = FAISS.from_documents(docs, embeddings)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "hjoUBm2nmi79",
        "outputId": "c15fae07-ec63-4ac1-b2c6-c1bdf7f1c556"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5c0c25ca-2fbd-4882-84b2-9dc1daa0e75f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5c0c25ca-2fbd-4882-84b2-9dc1daa0e75f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving HackathonInternalKnowledgeBase.csv to HackathonInternalKnowledgeBase (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "from IPython.display import Javascript\n",
        "\n",
        "def record_audio(filename='recorded.wav', duration=5):\n",
        "    js_code = \"\"\"\n",
        "    const sleep = time => new Promise(resolve => setTimeout(resolve, time));\n",
        "    const b2text = blob => new Promise(resolve => {\n",
        "      const reader = new FileReader();\n",
        "      reader.onloadend = () => resolve(reader.result);\n",
        "      reader.readAsDataURL(blob);\n",
        "    });\n",
        "    async function record() {\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n",
        "      const recorder = new MediaRecorder(stream);\n",
        "      const data = [];\n",
        "      recorder.ondataavailable = event => data.push(event.data);\n",
        "      recorder.start();\n",
        "      await sleep(\"\"\" + str(5 * 1000) + \"\"\");\n",
        "      recorder.stop();\n",
        "      await new Promise(resolve => recorder.onstop = resolve);\n",
        "      const blob = new Blob(data, { type: 'audio/wav' });\n",
        "      const base64 = await b2text(blob);\n",
        "      google.colab.kernel.invokeFunction('notebook.save_audio', [base64], {});\n",
        "    }\n",
        "    record();\n",
        "    \"\"\"\n",
        "    display(Javascript(js_code))\n",
        "\n",
        "def save_audio(base64_wav):\n",
        "    wav_data = base64.b64decode(base64_wav.split(',')[1])\n",
        "    with open(\"recorded.wav\", \"wb\") as f:\n",
        "        f.write(wav_data)\n",
        "    print(\"Audio saved as 'recorded.wav'\")\n",
        "\n",
        "output.register_callback('notebook.save_audio', save_audio)\n"
      ],
      "metadata": {
        "id": "l2l4iOIkmlP5"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe_audio_file(filename='converted.wav'):\n",
        "    recognizer = sr.Recognizer()\n",
        "    with sr.AudioFile(filename) as source:\n",
        "        audio = recognizer.record(source)\n",
        "    try:\n",
        "        text = recognizer.recognize_google(audio)\n",
        "        print(\"ðŸ“ Transcription:\", text)\n",
        "        return {\"transcription\": text, \"duration_seconds\": None}\n",
        "    except Exception as e:\n",
        "        print(\"Error in transcription:\", str(e))\n",
        "        return {\"error\": str(e)}\n"
      ],
      "metadata": {
        "id": "VUBXk5buml-D"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_memory = []\n",
        "\n",
        "def get_rag_context(query):\n",
        "    try:\n",
        "        docs = vectorstore.similarity_search(query, k=3)\n",
        "        return '\\n'.join([doc.page_content for doc in docs])\n",
        "    except Exception as e:\n",
        "        print(\"Error in RAG context:\", e)\n",
        "        return ''\n",
        "\n",
        "def chat_with_llm(user_input):\n",
        "    rag_context = get_rag_context(user_input)\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        *conversation_memory,\n",
        "        {\"role\": \"user\", \"content\": f\"{user_input}\\n\\nRelevant info:\\n{rag_context}\"}\n",
        "    ]\n",
        "    response = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\", messages=messages)\n",
        "    reply = response.choices[0].message['content']\n",
        "    conversation_memory.append({\"role\": \"user\", \"content\": user_input})\n",
        "    conversation_memory.append({\"role\": \"assistant\", \"content\": reply})\n",
        "    return reply\n"
      ],
      "metadata": {
        "id": "JaEjQ-bsmpLg"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def speak_text(text):\n",
        "    start = time.time()\n",
        "    tts = gTTS(text)\n",
        "    tts.save(\"response.mp3\")\n",
        "    duration = time.time() - start\n",
        "    return {\"audio\": \"response.mp3\", \"tts_duration\": round(duration, 2)}\n"
      ],
      "metadata": {
        "id": "Ut-IaceOmrZr"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi.responses import StreamingResponse\n",
        "from io import BytesIO\n",
        "\n",
        "@app.post(\"/upload_rag_docs\")\n",
        "async def upload_rag_docs(file: UploadFile = File(...)):\n",
        "    contents = await file.read()\n",
        "    df = pd.read_csv(BytesIO(contents))\n",
        "    # Chunking and embedding process\n",
        "    text_data = '\\n'.join(df.astype(str).apply(lambda row: ' '.join(row), axis=1).tolist())\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "    docs = splitter.create_documents([text_data])\n",
        "    vectorstore = FAISS.from_documents(docs, embeddings)\n",
        "    return {\"message\": \"Documents uploaded and indexed successfully\"}\n",
        "\n",
        "@app.post(\"/transcribe\")\n",
        "async def transcribe_audio(file: UploadFile = File(...)):\n",
        "    contents = await file.read()\n",
        "    with open(\"uploaded_audio.wav\", \"wb\") as f:\n",
        "        f.write(contents)\n",
        "    transcription = transcribe_audio_file(\"uploaded_audio.wav\")\n",
        "    return transcription\n",
        "\n",
        "@app.post(\"/chat\")\n",
        "async def chat(user_input: str):\n",
        "    response = chat_with_llm(user_input)\n",
        "    return {\"response\": response}\n",
        "\n",
        "@app.post(\"/speak\")\n",
        "async def speak(text: str):\n",
        "    audio = speak_text(text)\n",
        "    return FileResponse(audio[\"audio\"])\n",
        "\n",
        "@app.post(\"/converse\")\n",
        "async def converse(user_input: str, file: UploadFile = File(...)):\n",
        "    # Transcribe\n",
        "    contents = await file.read()\n",
        "    with open(\"uploaded_audio.wav\", \"wb\") as f:\n",
        "        f.write(contents)\n",
        "    transcription = transcribe_audio_file(\"uploaded_audio.wav\")\n",
        "\n",
        "    # Chat\n",
        "    response = chat_with_llm(user_input)\n",
        "\n",
        "    # Speak\n",
        "    audio = speak_text(response)\n",
        "\n",
        "    return {\"transcription\": transcription, \"response\": response, \"audio_file\": audio[\"audio\"], \"tts_duration\": audio[\"tts_duration\"]}\n",
        "\n"
      ],
      "metadata": {
        "id": "RA-YCoI1mtcJ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fastapi import FastAPI\n",
        "\n",
        "app = FastAPI()  # This line creates the FastAPI app instance and should be named `app`\n"
      ],
      "metadata": {
        "id": "GHTyV1ynn52h"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' app.py code\n",
        "\n",
        "from fastapi import FastAPI, File, UploadFile\n",
        "from fastapi.responses import FileResponse\n",
        "import openai\n",
        "import pandas as pd\n",
        "from io import BytesIO\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "# Initialize FastAPI instance\n",
        "app = FastAPI()\n",
        "\n",
        "# Example initialization for OpenAI API and vector store\n",
        "openai.api_key = \"Replace with your actual API key\"\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=openai.api_key)\n",
        "\n",
        "# Default route - should return a different message when you visit the base URL\n",
        "@app.get(\"/\")\n",
        "async def root():\n",
        "    return {\"message\": \"FastAPI is running!\"}\n",
        "\n",
        "# POST route to upload RAG documents\n",
        "@app.post(\"/upload_rag_docs\")\n",
        "async def upload_rag_docs(file: UploadFile = File(...)):\n",
        "    contents = await file.read()\n",
        "    df = pd.read_csv(BytesIO(contents))\n",
        "    # Chunking and embedding process\n",
        "    text_data = '\\n'.join(df.astype(str).apply(lambda row: ' '.join(row), axis=1).tolist())\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "    docs = splitter.create_documents([text_data])\n",
        "    vectorstore = FAISS.from_documents(docs, embeddings)\n",
        "    return {\"message\": \"Documents uploaded and indexed successfully\"}\n",
        "\n",
        "# POST route to transcribe audio\n",
        "@app.post(\"/transcribe\")\n",
        "async def transcribe_audio(file: UploadFile = File(...)):\n",
        "    contents = await file.read()\n",
        "    with open(\"uploaded_audio.wav\", \"wb\") as f:\n",
        "        f.write(contents)\n",
        "    transcription = transcribe_audio_file(\"uploaded_audio.wav\")\n",
        "    return transcription\n",
        "\n",
        "# POST route for chat\n",
        "@app.post(\"/chat\")\n",
        "async def chat(user_input: str):\n",
        "    response = chat_with_llm(user_input)\n",
        "    return {\"response\": response}\n",
        "\n",
        "# POST route for text-to-speech\n",
        "@app.post(\"/speak\")\n",
        "async def speak(text: str):\n",
        "    audio = speak_text(text)\n",
        "    return FileResponse(audio[\"audio\"])\n",
        "\n",
        "# POST route for the entire conversation flow (transcription + chat + speech)\n",
        "@app.post(\"/converse\")\n",
        "async def converse(user_input: str, file: UploadFile = File(...)):\n",
        "    # Transcribe\n",
        "    contents = await file.read()\n",
        "    with open(\"uploaded_audio.wav\", \"wb\") as f:\n",
        "        f.write(contents)\n",
        "    transcription = transcribe_audio_file(\"uploaded_audio.wav\")\n",
        "\n",
        "    # Chat\n",
        "    response = chat_with_llm(user_input)\n",
        "\n",
        "    # Speak\n",
        "    audio = speak_text(response)\n",
        "\n",
        "    return {\n",
        "        \"transcription\": transcription,\n",
        "        \"response\": response,\n",
        "        \"audio_file\": audio[\"audio\"],\n",
        "        \"tts_duration\": audio[\"tts_duration\"]\n",
        "    }\n",
        "\n",
        "# Example helper functions (implement the logic of transcribing, chatting, speaking, etc.)\n",
        "def transcribe_audio_file(filename: str):\n",
        "    # Example transcription logic\n",
        "    return {\"transcription\": \"This is a transcribed text from the audio file.\"}\n",
        "\n",
        "def chat_with_llm(user_input: str):\n",
        "    # Example LLM response logic\n",
        "    return f\"Response to: {user_input}\"\n",
        "\n",
        "def speak_text(text: str):\n",
        "    # Example TTS logic (you can replace it with actual TTS service)\n",
        "    audio_file = \"response.mp3\"  # Simulate TTS output\n",
        "    duration = 1.23  # Simulate TTS duration\n",
        "    return {\"audio\": audio_file, \"tts_duration\": duration}'''\n"
      ],
      "metadata": {
        "id": "IfFp771d0syX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IrLPShcoXXk",
        "outputId": "2fba5905-f421-4664-b82c-6e6a8a6f7e42"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.12-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.12-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!uvicorn app:app --reload --host 0.0.0.0 --port 8000\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5P7oR-GHr953",
        "outputId": "dddfaba7-efcd-4e2f-973b-ab712f41d2ef"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32mINFO\u001b[0m:     Will watch for changes in these directories: ['/content']\n",
            "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://0.0.0.0:8000\u001b[0m (Press CTRL+C to quit)\n",
            "\u001b[32mINFO\u001b[0m:     Started reloader process [\u001b[36m\u001b[1m9109\u001b[0m] using \u001b[36m\u001b[1mStatReload\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m9115\u001b[0m]\n",
            "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
            "\u001b[32mINFO\u001b[0m:     Application startup complete.\n",
            "\u001b[32mINFO\u001b[0m:     Shutting down\n",
            "\u001b[32mINFO\u001b[0m:     Waiting for application shutdown.\n",
            "\u001b[32mINFO\u001b[0m:     Application shutdown complete.\n",
            "\u001b[32mINFO\u001b[0m:     Finished server process [\u001b[36m9115\u001b[0m]\n",
            "\u001b[32mINFO\u001b[0m:     Stopping reloader process [\u001b[36m\u001b[1m9109\u001b[0m]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Replace 'your_authtoken' with your actual ngrok authtoken\n",
        "ngrok.set_auth_token(\"2zpyMLc6xP6vbnQn6tsqSED1Ekm_dubHmm6YoyZNgJm2y4Lc\")\n",
        "\n",
        "# Set up a tunnel to the FastAPI app (which is running on port 8000)\n",
        "public_url = ngrok.connect(8000)\n",
        "\n",
        "print(f\"FastAPI is live at: {public_url}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRWt3hcyoa0K",
        "outputId": "aa4c00a5-37a3-4686-dc42-3cda267e2d16"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastAPI is live at: NgrokTunnel: \"https://d69d44118400.ngrok-free.app\" -> \"http://localhost:8000\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Run FastAPI server in the background using subprocess\n",
        "subprocess.Popen([\"uvicorn\", \"app:app\", \"--reload\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"])\n",
        "\n",
        "# Set up ngrok to expose the FastAPI server to the public\n",
        "public_url = ngrok.connect(8000)\n",
        "print(f\"FastAPI is live at: {public_url}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7367tQtpMJL",
        "outputId": "78fdb4e2-b18a-40bb-bb50-be8944ca34b2"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastAPI is live at: NgrokTunnel: \"https://2e58ad635957.ngrok-free.app\" -> \"http://localhost:8000\"\n"
          ]
        }
      ]
    }
  ]
}